{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#!pip install albumentations==0.4.6\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "#!pip install webcolors\n",
    "import webcolors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image data 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/opt/ml/input/data/data_new')\n",
    "os.mkdir('/opt/ml/input/data/data_new/annotations')\n",
    "os.mkdir('/opt/ml/input/data/data_new/annotations/train')\n",
    "os.mkdir('/opt/ml/input/data/data_new/annotations/val')\n",
    "os.mkdir('/opt/ml/input/data/data_new/images')\n",
    "os.mkdir('/opt/ml/input/data/data_new/images/train')\n",
    "os.mkdir('/opt/ml/input/data/data_new/images/val')\n",
    "os.mkdir('/opt/ml/input/data/data_new/images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/input/data/train.json') as f:\n",
    "    train = json.load(f)\n",
    "with open('/opt/ml/input/data/val.json') as f:\n",
    "    val = json.load(f)\n",
    "with open('/opt/ml/input/data/test.json') as f:\n",
    "    test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset, testset = [], [], []\n",
    "for x in train['images']:\n",
    "    file_name = x['file_name']\n",
    "    trainset.append(file_name)\n",
    "for x in val['images']:\n",
    "    file_name = x['file_name']\n",
    "    valset.append(file_name)\n",
    "for x in test['images']:\n",
    "    file_name = x['file_name']\n",
    "    testset.append(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/opt/ml/input/data/batch_01_vt/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_01_vt/' + x in trainset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/train'+'/train_1' + x)\n",
    "dir_path = '/opt/ml/input/data/batch_02_vt/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_02_vt/' + x in trainset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/train'+'/train_2' + x)\n",
    "dir_path = '/opt/ml/input/data/batch_03/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_03/' + x in trainset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/train'+'/train_3' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/opt/ml/input/data/batch_01_vt/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_01_vt/' + x in valset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/val'+'/val_1' + x)\n",
    "dir_path = '/opt/ml/input/data/batch_02_vt/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_02_vt/' + x in valset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/val'+'/val_2' + x)\n",
    "dir_path = '/opt/ml/input/data/batch_03/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_03/' + x in valset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/val'+'/val_3' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/opt/ml/input/data/batch_01_vt/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_01_vt/' + x in testset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/test'+'/test_1' + x)\n",
    "dir_path = '/opt/ml/input/data/batch_02_vt/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_02_vt/' + x in testset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/test'+'/test_2' + x)\n",
    "dir_path = '/opt/ml/input/data/batch_03/'\n",
    "for x in os.listdir(dir_path):\n",
    "    if 'batch_03/' + x in testset:\n",
    "        os.rename(dir_path+x, '/opt/ml/input/data/data_new/images/test'+'/test_3' + x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json file 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train['images']:\n",
    "    if 'batch_01' in x['file_name']:\n",
    "        x['file_name'] = 'train/train_1' + x['file_name'][-8:]\n",
    "    elif 'batch_02' in x['file_name']:\n",
    "        x['file_name'] = 'train/train_2' + x['file_name'][-8:]\n",
    "    else:\n",
    "        x['file_name'] = 'train/train_3' + x['file_name'][-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in val['images']:\n",
    "    if 'batch_01' in x['file_name']:\n",
    "        x['file_name'] = 'val/val_1' + x['file_name'][-8:]\n",
    "    elif 'batch_02' in x['file_name']:\n",
    "        x['file_name'] = 'val/val_2' + x['file_name'][-8:]\n",
    "    else:\n",
    "        x['file_name'] = 'val/val_3' + x['file_name'][-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test['images']:\n",
    "    if 'batch_01' in x['file_name']:\n",
    "        x['file_name'] = 'test/test_1' + x['file_name'][-8:]\n",
    "    elif 'batch_02' in x['file_name']:\n",
    "        x['file_name'] = 'test/test_2' + x['file_name'][-8:]\n",
    "    else:\n",
    "        x['file_name'] = 'test/test_3' + x['file_name'][-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/input/data/data_new/train_new.json','w') as f:\n",
    "    json.dump(train, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/input/data/data_new/val_new.json','w') as f:\n",
    "    json.dump(val, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/input/data/data_new/test_new.json','w') as f:\n",
    "    json.dump(test, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
